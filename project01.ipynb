{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Speed Dating Partner Prediction\n",
    "\n",
    "Authors: Erinn Shu Han Lee, Lukáš Mikšovský\n",
    "\n",
    "## Introduction\n",
    "For our Python project, we have chosen [this dataset](https://www.kaggle.com/datasets/ulrikthygepedersen/speed-dating?resource=download) from the Kaggle website. It includes data from an experimental speed dating project that between 2002 and 2004.\n",
    "\n",
    "Our goal is to predict whether two individuals on a speed date will match at the end of the round of speed dating.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preliminary modules\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm, stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "random_seed = 123\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  (8378, 123)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 123 entries, has_null to match\n",
      "dtypes: float64(59), object(64)\n",
      "memory usage: 7.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[4-6]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[0-4]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  has_null  wave     gender   age  age_o  d_age   d_d_age  \\\n",
       "0      b''   1.0  b'female'  21.0   27.0    6.0  b'[4-6]'   \n",
       "1      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "2      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "3      b''   1.0  b'female'  21.0   23.0    2.0  b'[2-3]'   \n",
       "4      b''   1.0  b'female'  21.0   24.0    3.0  b'[2-3]'   \n",
       "\n",
       "                                       race  \\\n",
       "0  b'Asian/Pacific Islander/Asian-American'   \n",
       "1  b'Asian/Pacific Islander/Asian-American'   \n",
       "2  b'Asian/Pacific Islander/Asian-American'   \n",
       "3  b'Asian/Pacific Islander/Asian-American'   \n",
       "4  b'Asian/Pacific Islander/Asian-American'   \n",
       "\n",
       "                                     race_o samerace  ...  \\\n",
       "0            b'European/Caucasian-American'     b'0'  ...   \n",
       "1            b'European/Caucasian-American'     b'0'  ...   \n",
       "2  b'Asian/Pacific Islander/Asian-American'     b'1'  ...   \n",
       "3            b'European/Caucasian-American'     b'0'  ...   \n",
       "4               b'Latino/Hispanic American'     b'0'  ...   \n",
       "\n",
       "   d_expected_num_interested_in_me  d_expected_num_matches like  \\\n",
       "0                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "1                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "2                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "3                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "4                         b'[0-3]'                b'[3-5]'  6.0   \n",
       "\n",
       "  guess_prob_liked    d_like  d_guess_prob_liked  met  decision  decision_o  \\\n",
       "0              6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'        b'0'   \n",
       "1              5.0  b'[6-8]'            b'[5-6]'  1.0      b'1'        b'0'   \n",
       "2              NaN  b'[6-8]'            b'[0-4]'  1.0      b'1'        b'1'   \n",
       "3              6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'        b'1'   \n",
       "4              6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'        b'1'   \n",
       "\n",
       "   match  \n",
       "0   b'0'  \n",
       "1   b'0'  \n",
       "2   b'1'  \n",
       "3   b'1'  \n",
       "4   b'1'  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"speeddating.csv\")\n",
    "print('Dataset size: ', df.shape)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 122 independent variables in the dataset.\n",
    "\n",
    "Slightly less than half (59 columns are float64) are numeric data and the rest (64 columns are object(string)) are categorical data.\n",
    "\n",
    "The numeric data consists of each participants' rating of their date for the following qualitative attributes:\n",
    "1. Attractiveness\n",
    "2. Sincerity\n",
    "3. Intelligence\n",
    "4. Fun\n",
    "6. Ambition\n",
    "6. Shared Interests (e.g., sports, museums, clubbing, etc.)\n",
    "\n",
    "The categorical data gathered from the participants through a questionnaire to understand their background better are as follows:\n",
    "1. Demographics\n",
    "2. Dating habits\n",
    "3. Self-perception across key attributes\n",
    "4. Beliefs on what others find valuable in a mate\n",
    "5. Lifestyle information\n",
    "\n",
    "The raw data for both numeric and categorical data can be seen in the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data statistics\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plotted a bar chart to show how each category contributes to the dataset as a whole. It also helps us identify trends and patterns in the data in a simple way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.countplot(x='match', data=df, palette='RdBu')\n",
    "\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)\n",
    "\n",
    "plt.xticks([0,1], ['No', 'Yes'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as seen in the plot, most of the dates were unfortunately not matches. For instance, the short date was not a success 6998 times. Matches between two participants only occurred 1380 times.\n",
    "\n",
    "This means that our dataset is skewed towards the target of 0=\"no\". We have to keep this in mind when we evaluate the confusion matrix in the later section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will focus on cleaning the data to get the data ready for machine learning analysis. It will help to improve the accuracy and quality of these models and reduce dimensionality.\n",
    "\n",
    "First, it is important to ensure that our dataset is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null                0\n",
      "wave                    0\n",
      "gender                  0\n",
      "age                    95\n",
      "age_o                 104\n",
      "                     ... \n",
      "d_guess_prob_liked      0\n",
      "met                   375\n",
      "decision                0\n",
      "decision_o              0\n",
      "match                   0\n",
      "Length: 123, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we identified some missing data. Missing data will lead to biased or skewed interpretations of the data if left as it is. Hence, we will be imputing these missing values to help maintain the consistency and integrity of data for further processing, analysis, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null              0\n",
      "wave                  0\n",
      "gender                0\n",
      "age                   0\n",
      "age_o                 0\n",
      "                     ..\n",
      "d_guess_prob_liked    0\n",
      "met                   0\n",
      "decision              0\n",
      "decision_o            0\n",
      "match                 0\n",
      "Length: 123, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[df.isnull().any(axis=0)]:\n",
    "    df[i].fillna(df[i].mean(),inplace=True)\n",
    "\n",
    "# Re-check if there are any missing data after imputing\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to utilize machine learning algorithms and statistical techniques in the later sections, we will first convert the categorical and textual data into numeric data. This will help the algorithm to use the data and extract insights from it. The conversion process will recognize patterns, relationships, and similarities in the data.\n",
    "\n",
    "For this dataset, we will use ordinal encoder. The encoder will assign a unique integer value to each category based on their order or rank in the hierarchy. It ensures that the order of the data is maintained and enable the algorithm to understand the relative relationships between the different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 123 entries, has_null to match\n",
      "dtypes: float64(123)\n",
      "memory usage: 7.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  wave  gender   age  age_o  d_age  d_d_age  race  race_o  \\\n",
       "0       0.0   1.0     0.0  21.0   27.0    6.0      2.0   1.0     3.0   \n",
       "1       0.0   1.0     0.0  21.0   22.0    1.0      0.0   1.0     3.0   \n",
       "2       0.0   1.0     0.0  21.0   22.0    1.0      0.0   1.0     1.0   \n",
       "3       0.0   1.0     0.0  21.0   23.0    2.0      1.0   1.0     3.0   \n",
       "4       0.0   1.0     0.0  21.0   24.0    3.0      1.0   1.0     4.0   \n",
       "\n",
       "   samerace  ...  d_expected_num_interested_in_me  d_expected_num_matches  \\\n",
       "0       0.0  ...                              0.0                     1.0   \n",
       "1       0.0  ...                              0.0                     1.0   \n",
       "2       1.0  ...                              0.0                     1.0   \n",
       "3       0.0  ...                              0.0                     1.0   \n",
       "4       0.0  ...                              0.0                     1.0   \n",
       "\n",
       "   like  guess_prob_liked  d_like  d_guess_prob_liked  met  decision  \\\n",
       "0   7.0               6.0     1.0                 1.0  0.0       1.0   \n",
       "1   7.0               5.0     1.0                 1.0  1.0       1.0   \n",
       "2   7.0               NaN     1.0                 0.0  1.0       1.0   \n",
       "3   7.0               6.0     1.0                 1.0  0.0       1.0   \n",
       "4   6.0               6.0     1.0                 1.0  0.0       1.0   \n",
       "\n",
       "   decision_o  match  \n",
       "0         0.0    0.0  \n",
       "1         0.0    0.0  \n",
       "2         1.0    1.0  \n",
       "3         1.0    1.0  \n",
       "4         1.0    1.0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        oe = OrdinalEncoder()\n",
    "        oe.fit(df[[col]])\n",
    "        df[col] = oe.fit_transform(df[[col]])\n",
    "        \n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data\n",
    "X = df.drop(['match'], axis=1)\n",
    "y = df['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6283, 122), (6283,), (2095, 122), (2095,))"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our data, we we have decided to utilize logistic regression as the outcome variable is categorical (\"yes\" or \"no\") and the input variables contain both numeric and categorical data.\n",
    "\n",
    "It is important to note that logistic regression assumes a linear relationship between the input variables and the log-odds of the outcome variable. Hence, it is sensitive to outliers and multicollinearity. With the prior data preprocessing and transformiation, we believe this model will be able to best predict the probability of two individuals matching at the end of the round of speed dating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689737470167065"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg into the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy of the model\n",
    "logreg_accuracy = logreg.score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above accuracy score of 0.96897 (rounded to 5 decimal places) indicates a close to perfect classification accuracy, as 0 indicates complete misclassification and 1 indiccates perfect classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaparameter Tuning - Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To systematically search through the range of hyperparameters to find the best combination of values to optimize the logistic regression model performance, we perform GridSearchCV.\n",
    "\n",
    "GridSearchCV results in higher accuracy on the test set and ensures that the model is not overfitting to the training set and is generalizing well to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Specify the hyperparameter as a dictionary\n",
    "param_grid = {'n_neighbors': np.arrange(1,50)}\n",
    "\n",
    "# Create grid search\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Performs the actual grid search inplace\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Returns the hyperparameter that performs the best\n",
    "logreg_cv.best_params_\n",
    "\n",
    "# Returns the mean cross-validation score over that fold\n",
    "logreg_cv.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<insert explanation on the results>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the logistic regression classifier, we will use a Receiving Operating Characteristic (ROC) curve by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute predicted probabilities from logreg before using a threshold to predict the label\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "            \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above ROC curve, it is noted that the curve is close to the top left corner of the plot, which corresponds to high TPR and low FPR. Hence, we can say that the model is able to distinguish between the positive and negative classes well across all possible threshold values.\n",
    "\n",
    "To further illustrate this metric, we use the Area under the ROC curve (AUC) to evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute predicted probabilities\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute AUC score\n",
    "roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Compute cross-validated AUC scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_auc = cross_val_scores(logreg, X, y, cv=5, scoring='roc auc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the AUC score is close to 1, it indicates a good performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building - Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we will build a Random Forest classification model to contrast it with the Logistic Regression classification model.\n",
    "\n",
    "Random Forest is a tree-based model where multiple decision trees are trained on random subsets of data and their outputs are combined to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the random forest model with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<insert explanation on the results>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaparameter Tuning - Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the logistic regression classification, we will use GridSearchCv to find the best hyperparameters for the Random Forest Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameters\n",
    "parameters = {\"max_depth\": [5, 10, 15]}\n",
    "\n",
    "# Create grid search\n",
    "grid_search = GridSearchCV(random_forest_model, parameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "grid_search.best_params_\n",
    "\n",
    "# Get best model\n",
    "grid_search.best_estimator_\n",
    "\n",
    "# Get best score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<insert explanation on the results>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the Random Forest classifier to be compared to that of the Logistic Regression Classifier, we will also plot the ROC curve at various threshold settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROC curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# ROC curve\n",
    "ax = plt.gca()\n",
    "rfc_disp = RocCurveDisplay.from_estimator(grid_search.best_estimator_, X_val, y_val, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<insert explanation on the results>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the above two classification models, we will create a confusion matrix for both models to compare the actual values of the target variable with the predicted values in the model. This will quantify the accuracy of a classification model.\n",
    "\n",
    "Here, the confusion matrix contains four values: true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1728\n",
      "         1.0       0.94      0.88      0.91       367\n",
      "\n",
      "    accuracy                           0.97      2095\n",
      "   macro avg       0.96      0.94      0.95      2095\n",
      "weighted avg       0.97      0.97      0.97      2095\n",
      "\n",
      "[[1706   22]\n",
      " [  43  324]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix for Logistic Regression\n",
    "print(classification_report(y_test, log_pred))\n",
    "print(confusion_matrix(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1728\n",
      "         1.0       1.00      1.00      1.00       367\n",
      "\n",
      "    accuracy                           1.00      2095\n",
      "   macro avg       1.00      1.00      1.00      2095\n",
      "weighted avg       1.00      1.00      1.00      2095\n",
      "\n",
      "[[1728    0]\n",
      " [   0  367]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix for Random Forest\n",
    "print(classification_report(y_test, tree_pred))\n",
    "print(confusion_matrix(y_test, tree_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, ... <insert explanation on the results>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ARCHIVE CODE (to be delated later if not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "tree_pred = tree.predict(X_test)\n",
    "tree.score(X_test, y_test)\n",
    "\n",
    "# Get predictions\n",
    "random_forest_prediction = grid_search.best_estimator_.predict(X_val)\n",
    "random_forest_prediction[:10]\n",
    "\n",
    "# Get report of model\n",
    "random_forest_report = classification_report(y_val, random_forest_prediction, output_dict=True)\n",
    "random_forest_report_df = pd.DataFrame(random_forest_report).transpose()\n",
    "random_forest_report_df\n",
    "\n",
    "# Get confusion matrix\n",
    "random_forest_confusion_matrix = confusion_matrix(y_val, random_forest_prediction)\n",
    "random_forest_confusion_matrix\n",
    "\n",
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(grid_search.best_estimator_, X_val, y_val, cmap=\"RdPu\")\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(grid_search.best_estimator_.feature_importances_, index=X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importance.plot(kind='bar', figsize=(20, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
